{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHKlqlI2Zk6Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCSgEDdzZnMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets,transforms,models\n",
        "from torch import nn,optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import *\n",
        "\n",
        "import time\n",
        "import json\n",
        "import copy\n",
        "import os\n",
        "import glob\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "torch.backends.cudnn.enabled = False\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "# torch.backends.cudnn.enabled\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adKgILv2ZurJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tansform with data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(30),\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.ColorJitter(brightness=0.5, contrast=0, saturation=0.2, hue=0.1),\n",
        "        #transforms.RandomResizedCrop(299),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.3853, 0.3780, 0.3631], [0.1965, 0.1920, 0.1924])\n",
        "        # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        #transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.CenterCrop(299),\n",
        "        transforms.ColorJitter(brightness=0.5, contrast=0, saturation=0.2, hue=0.1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.3853, 0.3780, 0.3631], [0.1965, 0.1920, 0.1924])\n",
        "        # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    \n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(256),                                  \n",
        "        transforms.CenterCrop(224),\n",
        "        #transforms.CenterCrop(299),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.3473, 0.3418, 0.3290],[0.1896, 0.1837, 0.1802])\n",
        "        # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOTWOtEEZ1E-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading in the dataset\n",
        "\n",
        "train_dir = \"/content/drive/My Drive/Colab Notebooks/535_Project/data/train\"  #path to data\n",
        "label_dir = 'names.csv'\n",
        "\n",
        "batch_size=32\n",
        "\n",
        "dataset = datasets.ImageFolder(train_dir,transform=data_transforms['train'])\n",
        "\n",
        "# splitting data\n",
        "valid_size  = int(0.1 * len(dataset))\n",
        "train_size = len(dataset) - valid_size\n",
        "dataset_sizes = {'train': train_size, 'val': valid_size}\n",
        "\n",
        "train_dataset, valid_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size])\n",
        "\n",
        "# Loading datasets into dataloader \n",
        "dataloaders = {'train': DataLoader(train_dataset, batch_size = batch_size, shuffle = True),\n",
        "              'val': DataLoader(valid_dataset, batch_size = batch_size, shuffle = True)}\n",
        "\n",
        "\n",
        "\n",
        "print(\"Total Number of Samples: \",len(dataset))\n",
        "print(\"Number of Samples in Train: \",len(train_dataset))\n",
        "print(\"Number of Samples in Valid: \",len(valid_dataset))\n",
        "print(\"Number of Classes: \",len(dataset.classes))\n",
        "\n",
        "print(dataset.classes[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPoPyPpXZ-nN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.resnet50(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 4)  #change this to the desired number of classes (in this case 4)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# criterion = nn.NLLLoss()\n",
        "\n",
        "=\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 4 epochs\n",
        "sched = optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUT0NjxDaSid",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, sched, num_epochs=5,device='cuda'):\n",
        "    start = time.time()\n",
        "    train_results = []\n",
        "    valid_results = []\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        \n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        \n",
        "        print('-' * 10)\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':            \n",
        "              model.train()  # Set model to training mode\n",
        "            else:\n",
        "              model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        #sched.step()\n",
        "                        loss.backward()\n",
        "                        \n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "            \n",
        "            # calculate average time over an epoch\n",
        "            #elapshed_epoch = time.time() - start/            \n",
        "            #print('Epoch {}/{} - completed in: {:.0f}m {:.0f}s'.format(epoch+1, num_epochs,elapshed_epoch // 60, elapshed_epoch % 60))\n",
        "            \n",
        "            if(phase == 'train'):\n",
        "              train_results.append([epoch_loss,epoch_acc])\n",
        "            if(phase == 'val'):\n",
        "              #sched.step(epoch_acc)\n",
        "              valid_results.append([epoch_loss,epoch_acc])\n",
        "                                   \n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model (Early Stopping) and Saving our model, when we get best accuracy\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())       \n",
        "                model_save_name = \"ResNet50.pt\"\n",
        "                path = F\"/content/drive/My Drive/Colab Notebooks/535_Project/data/{model_save_name}\"\n",
        "                torch.save(model.state_dict(), path)        \n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - start\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    #load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    \n",
        "    return model,train_results,valid_results\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qo2RqafRacTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train new data\n",
        "\n",
        "epochs = 20\n",
        "model.to(device)\n",
        "model,train_results,valid_results = train_model(model, criterion, optimizer, sched, epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag8itAATai7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load saved model:\n",
        "model.load_state_dict(torch.load('/content/drive/My Drive/Colab Notebooks/535_Project/data/ResNet50_color.pt'))\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ESTXsxiaqC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import os\n",
        "import cv2\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "import csv\n",
        "import shutil\n",
        "from PIL import ImageFile\n",
        "\n",
        "\n",
        "\n",
        "#Align paths\n",
        "class ImageFolderWithPaths(datasets.ImageFolder):\n",
        "    \"\"\"Custom dataset that includes image file paths. Extends\n",
        "    torchvision.datasets.ImageFolder\n",
        "    \"\"\"\n",
        "\n",
        "    # override the __getitem__ method. this is the method that dataloader calls\n",
        "    def __getitem__(self, index):\n",
        "        # this is what ImageFolder normally returns \n",
        "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
        "        # the image file path\n",
        "        path = self.imgs[index][0]\n",
        "        # make a new tuple that includes original and the path\n",
        "        tuple_with_path = (original_tuple + (path,))\n",
        "        return tuple_with_path\n",
        "\n",
        "\n",
        "\n",
        "test_dir = \"/content/drive/My Drive/Colab Notebooks/535_Project/data/test_original\"\n",
        "# image_dataset = datasets.ImageFolder(test_dir,transform=data_transforms['test'])\n",
        "image_dataset = ImageFolderWithPaths(test_dir, transform=data_transforms['test'])\n",
        "  \n",
        "testloader = torch.utils.data.DataLoader(image_dataset, batch_size=64,\n",
        "                                             shuffle=True, num_workers=2)\n",
        "  \n",
        "# class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM7VXBUFa2Q8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test network on test data\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "batch_size = 10\n",
        "output_list = []\n",
        "image_names = []\n",
        "\n",
        "for i, (images, labels, paths) in enumerate(testloader, 0):\n",
        "    images = images.to(device)\n",
        "    outputs = model.forward(images)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "    for i in range(len(paths)):\n",
        "        filename = paths[i]\n",
        "        filename = (Path(filename).parts[-2] + '/' + Path(filename).stem)\n",
        "        filename= filename[:-6]\n",
        "        label = preds[i].item()\n",
        "        image_names.append(filename)\n",
        "        output_list.append(str(label))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_pYxUHVa5b4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save to csv\n",
        "df = pd.DataFrame({'guid/image': image_names, 'label': output_list})\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "=\n",
        "df.to_csv('/content/drive/My Drive/Colab Notebooks/535_Project/Predictions/predictions_ResNet_v4.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}